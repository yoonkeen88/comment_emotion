import pandas as pd
import multiprocessing as mp
from tqdm import tqdm
from transformers import pipeline
import os
import argparse

LABELS = ["ê¸ì •", "ë¹„íŒ", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ê¸°ëŒ€", "ì¤‘ë¦½"]
COMMENT_COLUMN = "comment"
DATE_COLUMN = "date"

# âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
def init_model():
    global classifier
    classifier = pipeline(
        "zero-shot-classification",
        model="joeddav/xlm-roberta-large-xnli",
        framework="pt",
        device=-1
    )

# âœ… ê°œë³„ ë¬¸ì¥ ì²˜ë¦¬
def analyze_sentiment(text):
    try:
        output = classifier(text, LABELS)
        return {
            "top_emotion": output["labels"][0],
            **{label: output["scores"][i] for i, label in enumerate(output["labels"])}
        }
    except:
        return {
            "top_emotion": "error",
            **{label: None for label in LABELS}
        }

# âœ… ë©”ì¸ ì‹¤í–‰
def main(args):
    df = pd.read_csv(args.input)
    df = df.dropna(subset=[COMMENT_COLUMN]).reset_index(drop=True)
    comments = df[COMMENT_COLUMN].tolist()
    total = len(comments)
    chunks = [comments[i:i + args.chunk_size] for i in range(0, total, args.chunk_size)]

    os.makedirs(args.output_dir, exist_ok=True)

    for i, chunk in enumerate(chunks):
        print(f"ğŸ”„ ì²­í¬ {i+1}/{len(chunks)} ë¶„ì„ ì¤‘...")
        with mp.Pool(processes=args.num_proc, initializer=init_model) as pool:
            results = list(tqdm(pool.imap(analyze_sentiment, chunk), total=len(chunk)))

        result_df = pd.DataFrame(results)
        original_meta = df.iloc[i * args.chunk_size : i * args.chunk_size + len(chunk)].reset_index(drop=True)
        merged_df = pd.concat([original_meta, result_df], axis=1)

        save_path = os.path.join(args.output_dir, f"ê°ì •ë¶„ì„_ê²°ê³¼_part{i+1}.csv")
        merged_df.to_csv(save_path, index=False)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

    print("ğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")

# âœ… argparse ì¸ì ì²˜ë¦¬
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="ë¶„ì„í•  CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output_dir", default="result_parts", help="ê²°ê³¼ ì €ì¥ í´ë”")
    parser.add_argument("--chunk_size", type=int, default=1000, help="ì²­í¬ í¬ê¸°")
    # â¬‡ï¸ argparseì— ì¶”ê°€
    parser.add_argument("--num_proc", type=int, default=2, help="ì‚¬ìš©í•  ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜")
    args = parser.parse_args()

    main(args)