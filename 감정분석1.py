import torch
import subprocess

def print_gpu_memory():
    if torch.cuda.is_available():
        print("ğŸ–¥ï¸ GPU ìƒíƒœ í™•ì¸:")
        try:
            # torch ê¸°ë°˜ ì²´í¬
            allocated = torch.cuda.memory_allocated(0) / 1024**2
            reserved = torch.cuda.memory_reserved(0) / 1024**2
            print(f"  - CUDA ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.2f} MB (í• ë‹¹ë¨), {reserved:.2f} MB (ì˜ˆì•½ë¨)")

            # nvidia-smië¡œë„ ì²´í¬ (ì„ íƒì‚¬í•­)
            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            print("  - NVIDIA-SMI ìƒíƒœ â†“")
            print(result.stdout.split("Processes")[1])  # ì¶œë ¥ ì¼ë¶€ë§Œ í‘œì‹œ
        except Exception as e:
            print(f"âš ï¸ GPU ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€: GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
import pandas as pd
from tqdm import tqdm
from transformers import pipeline
import os
import argparse
import torch

LABELS = ["ê¸ì •", "ë¹„íŒ", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ê¸°ëŒ€", "ì¤‘ë¦½"]
COMMENT_COLUMN = "comment"
DATE_COLUMN = "date"

# âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
def init_model():
    device = 0 if torch.cuda.is_available() else -1
    print(f"âœ… ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘ (device={device})")
    return pipeline(
        "zero-shot-classification",
        model="joeddav/xlm-roberta-large-xnli",
        framework="pt",
        device=device
    )

# âœ… ê°œë³„ ë¬¸ì¥ ì²˜ë¦¬
def analyze_sentiment(text, classifier):
    try:
        output = classifier(text, LABELS)
        return {
            "top_emotion": output["labels"][0],
            **{label: output["scores"][i] for i, label in enumerate(output["labels"])}
        }
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "top_emotion": "error",
            **{label: None for label in LABELS}
        }

# âœ… ë©”ì¸ ì‹¤í–‰
def main(args):
    df = pd.read_csv(args.input)
    df = df.dropna(subset=[COMMENT_COLUMN]).reset_index(drop=True)
    comments = df[COMMENT_COLUMN].tolist()
    total = len(comments)
    chunks = [comments[i:i + args.chunk_size] for i in range(0, total, args.chunk_size)]

    os.makedirs(args.output_dir, exist_ok=True)
    classifier = init_model()

    start_chunk_index = args.start_chunk - 1

    for i, chunk in enumerate(chunks):
        if i < start_chunk_index:
            continue

        save_path = os.path.join(args.output_dir, f"ê°ì •ë¶„ì„_ê²°ê³¼_part{i+1}.csv")
        if os.path.exists(save_path):
            print(f"â­ï¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ì²­í¬ {i+1}ë¥¼ ê±´ë„ˆ<binary data, 2 bytes>ë‹ˆë‹¤: {save_path}")
            continue

        print(f"ğŸ”„ ì²­í¬ {i+1}/{len(chunks)} ë¶„ì„ ì¤‘...")
        print_gpu_memory()  # âœ… GPU ìƒíƒœ ì¶œë ¥
        results = [analyze_sentiment(text, classifier) for text in tqdm(chunk)]

        result_df = pd.DataFrame(results)
        original_meta = df.iloc[i * args.chunk_size : i * args.chunk_size + len(chunk)].reset_index(drop=True)
        merged_df = pd.concat([original_meta, result_df], axis=1)

        merged_df.to_csv(save_path, index=False)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

    print("ğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")

# âœ… argparse ì¸ì ì²˜ë¦¬
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="ë¶„ì„í•  CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output_dir", default="result_parts", help="ê²°ê³¼ ì €ì¥ í´ë”")
    parser.add_argument("--chunk_size", type=int, default=1000, help="ì²­í¬ í¬ê¸°")
    parser.add_argument("--start_chunk", type=int, default=1, help="ì‹œì‘í•  ì²­í¬ ë²ˆí˜¸")
    args = parser.parse_args()

    main(args)
