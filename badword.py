import pandas as pd
import re
from multiprocessing import Pool, cpu_count
import os

# ìš•ì„¤ íƒì§€ìš© ì •ê·œì‹ íŒ¨í„´
profanity_patterns = [
    r'ã…ˆ+ê°™[ë‹¤ì€]',
    r'ã……+ã…‚',
    r'ã…‚+ã……',
    r'ã„±+ã……ã„²',
    r'ì¢†',
    r'ì”¨+ë°œ',
    r'ë¯¸+ì¹œ',
    r'ã…ˆ+ã„´',
]

# ìš•ì„¤ ì •ê·œí™” ë£°
def normalize_profanity(text):
    patterns = {
        r'ã…ˆ+ê°™[ë‹¤ì€]': 'ì§œì¦ë‚œë‹¤',
        r'ã……+ã…‚': 'ì§„ì§œ ì—´ë°›ëŠ”ë‹¤',
        r'ã…‚+ã……': 'ë‹µë‹µí•œ ì‚¬ëžŒ',
        r'ã„±+ã……ã„²': 'ë¶ˆì¾Œí•œ ì‚¬ëžŒ',
        r'ì¢†': 'ì •ë§ ì‹«ì€',
        r'ì”¨+ë°œ': 'ì •ë§ í™”ê°€ ë‚œ',
        r'ë¯¸+ì¹œ': 'ë§ë„ ì•ˆ ë˜ëŠ”',
        r'ã…ˆ+ã„´': 'ì§„ì§œ',
        r'ì¡¸ë¼': 'ë§¤ìš°',
        r'ê°œ+ê°™[ë‹¤ì€]': 'ë§¤ìš° ì§œì¦ë‚˜ëŠ”',
        r'ã…‰ã…‰': 'ì§œì¦ë‚˜',
        r'ã…‹' : 'ì›ƒìŒ',
        r'ã…Ž' : 'ì›ƒìŒ',
    }
    for pattern, replacement in patterns.items():
        text = re.sub(pattern, replacement, text)
    return text

# í•œêµ­í˜• ì´ëª¨ì§€ ì œê±°ìš© ì •ê·œì‹ íŒ¨í„´
korean_emojis_patterns = [
    r'[ã…‹ã…Ž]{2,}',        # ã…‹ã…‹, ã…Žã…Ž
    r'[ã…œã… ]{1,}',        # ã… ã… , ã…œã…œ
    r'[-~_^]{2,}',        # ^^, ^~^, ~~ ë“±
    r'ã…¡\.ã…¡', r'ã…‡_ã…‡',   # ì–¼êµ´í˜• ì´ëª¨ì§€
    r'ã…¡',
    r'~',
    r'>_<', r'^_^', r'T_T',
    r'í—', r'ì­', r'ì›…', r'ì—¥', r'ì•„ë†”'
]

def remove_korean_emojis(text):
    for pattern in korean_emojis_patterns:
        text = re.sub(pattern, '', text)
    return text

def contains_profanity(text):
    for pat in profanity_patterns:
        if re.search(pat, text):
            return True
    return False

def process_row(row):
    text = str(row['comment'])
    if contains_profanity(text):
        normalized = normalize_profanity(text)
        normalized = remove_korean_emojis(normalized)
        if contains_profanity(normalized):
            return None
        else:
            return {'date': row['date'], 'comment': normalized}
    else:
        clean = remove_korean_emojis(text)
        return {'date': row['date'], 'comment': clean}

def process_file_parallel(input_path):
    df = pd.read_csv(f'split_data/{input_path}')
    rows = df.to_dict(orient='records')

    with Pool(cpu_count()) as pool:
        results = pool.map(process_row, rows)

    filtered = [r for r in results if r is not None]
    return pd.DataFrame(filtered)

import time
def main():
    print(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    input_files = [f'comments_part{i}.csv' for i in range(1, 4)]
    os.makedirs('processed_comments', exist_ok=True)

    all_dfs = []
    for file in input_files:
        print(f"â–¶ ì²˜ë¦¬ ì‹œìž‘: {file}")
        processed_df = process_file_parallel(file)
        print(f"âœ… {file} ì²˜ë¦¬ ì™„ë£Œ, ê±´ìˆ˜: {len(processed_df)}")
        all_dfs.append(processed_df)

        processed_df.to_csv(f'processed_comments/processed_{file}', index=False)

    final_df = pd.concat(all_dfs).reset_index(drop=True)
    final_df.to_csv('processed_comments/final_processed_comments.csv', index=False)
    print(f"ðŸŽ‰ ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ, ì´ ê±´ìˆ˜: {len(final_df)}")
    print(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))

if __name__ == "__main__":
    main()
