import pandas as pd
import re
from multiprocessing import Pool, cpu_count
import os
import time

# ê°ì •ë³„ ëŒ€í‘œ ë‹¨ì–´ ì‚¬ì „ (emotion_dictionary.py ê¸°ë°˜)
emotion_dict = {
    "ê¸ì •": ["ì¢‹ë‹¤", "ê¸°ì˜ë‹¤", "ë§Œì¡±", "í–‰ë³µ", "ì‚¬ë‘", "ê°ì‚¬", "ì¦ê²ë‹¤", "ì˜í–ˆë‹¤", "ì¹­ì°¬", "í›Œë¥­í•˜ë‹¤"],
    "ê¸°ëŒ€": ["ê¸°ëŒ€", "ì„¤ë ˆë‹¤", "ê¸°ë‹¤ë¦¬ë‹¤", "í¬ë§", "ë°”ë¼ë‹¤", "ê¶ê¸ˆí•˜ë‹¤", "í¥ë¯¸", "ê´€ì‹¬", "ê¸°ëŒ€ê°", "í¬ë§ì "],
    "ë¹„íŒ": ["ë¬¸ì œ", "ë¶€ì¡±", "ê°œì„ ", "ì§€ì ", "ë¹„íš¨ìœ¨", "ë¶ˆí¸", "ë¶ˆë§Œ", "ìš°ë ¤", "ë¶ˆí™•ì‹¤", "ì˜ë¬¸"],
    "ì‹¤ë§": ["ì‹¤ë§", "ì•„ì‰½ë‹¤", "í›„íšŒ", "ì§€ì¹˜ë‹¤", "ë¶ˆì¾Œ", "ë‚™ë‹´", "í—ˆíƒˆ", "í•œìˆ¨"],
    "ë¶„ë…¸": ["í™”ë‚˜ë‹¤", "ì—´ë°›ë‹¤", "ì§œì¦", "ë¹¡ì¹˜ë‹¤", "ë¶„ë…¸", "ì—­ê²¹ë‹¤", "í­ë°œ", "ì‹«ë‹¤", "ì§œì¦ë‚˜", "í­ë ¥ì "],
    "ì¤‘ë¦½": ["ê·¸ë ‡ë‹¤", "ê·¸ëƒ¥", "ë³´í†µ", "í‰ë²”", "ë¬´ë‚œ", "ì˜ëª¨ë¥´ê² ë‹¤", "ì•„ë¬´ìƒê°ì—†ë‹¤", "ì¤‘ë¦½", "í‰ë²”í•˜ë‹¤", "ì¼ë°˜ì "]
}

# ìš•ì„¤, ë¹„ì†ì–´, ì‹ ì¡°ì–´, ì¤„ì„ë§ ì •ê·œí™” ì‚¬ì „
normalization_dict = {
    # ======================================================
    # 1. ì‹¬í•œ ìš•ì„¤ ë° ë¹„í•˜ í‘œí˜„
    # ======================================================
    r'ê°œë¼ì§€|ê°œë¼ì¥': 'ë¹„í•˜ ë°œì–¸',
    r'(ã……|ã…†)(ã…‚|ë°œ|íŒ”|ë²Œ|ë°”|íŒŒ|ã…|ã…ƒ)': 'ìš•ì„¤',
    r'(ã…ˆ|ì¢†|ì¡·|ì¡°ã…ˆ)(ê°™|ê°€|ê¹Œ)': 'ë§¤ìš° ë³„ë¡œì¸',
    r'(ã…ˆ|ì¦‚|ã…ˆã…—ã…ˆ|ã…ˆã…—ã……)ã„´': 'ë§¤ìš°',
    r'(ã…|ë¯¸)(ã…Š|ì¹œ|ì·¬|ì¹œ)': 'ë¹„ì •ìƒì ì¸',
    r'(ã…‚|ë³‘)(ã……|ì‹ |ì‰°)': 'ë°”ë³´',
    r'(ã…ˆ|ì§€)(ã„¹|ë„|ëŸ´)': 'í—›ì†Œë¦¬',
    r'(ã„·|ë“±)(ã……|ì‹ )': 'ë°”ë³´',
    r'(ã„±|ê°œ)(ã……|ìƒˆ|ì„€)(ã„²|ë¼)': 'ë‚˜ìœë†ˆ',
    r'ìƒˆë¼': 'ë¹„í•˜',
    r'êº¼ì ¸': 'ë‚˜ê°€',
    r'ì¡´ë‚˜|ì¡¸ë¼': 'ë§¤ìš°',
    r'ì•„ê°€ë¦¬': 'ì…',
    r'ë‹¥ì³': 'ì¡°ìš©íˆ í•´',

    # ======================================================
    # 2. ì •ì¹˜/ì‚¬íšŒ ê´€ë ¨ ì€ì–´ ë° ë¹„í•˜ í‘œí˜„
    # ======================================================
    r'ê¸°ë ˆê¸°': 'ê¸°ì ë¹„í•˜',
    r'ë¬¸ì¬ì•™|ë¬¸ì£„ì¸': 'ë¬¸ì¬ì¸ ëŒ€í†µë ¹ ë¹„í•˜',
    r'ë°•ê·¸ë„¤|ë‹­ê·¸ë„¤': 'ë°•ê·¼í˜œ ëŒ€í†µë ¹ ë¹„í•˜',
    r'ì´ëª…ë°•|ì¥ë°•ì´': 'ì´ëª…ë°• ëŒ€í†µë ¹ ë¹„í•˜',
    r'í‹€ë”±ì¶©|í‹€ë”±': 'ë…¸ì¸ ë¹„í•˜',
    r'ë§˜ì¶©': 'ì–´ë¨¸ë‹ˆ ë¹„í•˜',
    r'í•œë…€ì¶©|í•œë‚¨ì¶©': 'ì„±ë³„ ë¹„í•˜',
    r'ì¢Œë¹¨|ì¢Œì¢€': 'ì¢ŒíŒŒ ë¹„í•˜',
    r'ìˆ˜êµ¬ê¼´í†µ': 'ìš°íŒŒ ë¹„í•˜',
    r'ëŒ€ê¹¨ë¬¸': 'ë¬¸ì¬ì¸ ëŒ€í†µë ¹ ì§€ì§€ì ë¹„í•˜',

    # ======================================================
    # 3. ì¼ë°˜ ì€ì–´, ì¤„ì„ë§, ì´ˆì„±
    # ======================================================
    # --- ê¸ì • ---
    r'ì¡´ë§›|ì¡´ë§›íƒ±|JMT': 'ë§¤ìš° ë§›ìˆëŠ”',
    r'ê¿€ì¼': 'ë§¤ìš° ì¬ë¯¸ìˆëŠ”',
    r'ê°œì´ë“': 'í° ì´ìµ',
    r'í•µì¼': 'ë§¤ìš° ì¬ë¯¸ìˆëŠ”',
    # --- ë¶€ì • ---
    r'ë…¸ì¼': 'ì¬ë¯¸ì—†ëŠ”',
    r'ê·¹í˜': 'ë§¤ìš° í˜ì˜¤ìŠ¤ëŸ¬ìš´',
    r'í—¬ì¡°ì„ |í—¬.+': 'ë§¤ìš° í˜ë“  ìƒí™©',
    # --- ì´ˆì„± ---
    r'ã…‡ã…ˆ': 'ì¸ì •',
    r'ã„¹ã…‡': 'ì •ë§',
    r'ã„±ã……': 'ê°ì‚¬',
    r'ã……ã…Œã…Š': 'ìƒìœ„ê¶Œ',
    r'ã…ã…Œã…Š': 'í‰ê· ',
    r'ã…ã…Œã…Š': 'í•˜ìœ„ê¶Œ',
    r'ã„·ã„·': 'ë†€ëŒ',
    r'ã…‚ã„·ã…‚ã„·': 'ë¶€ë“¤ë¶€ë“¤',
    r'ã…‡ã…‡': 'ì‘',
    r'ã„´ã„´': 'ì•„ë‹ˆ',
    r'ã…‰ã…‰': 'ì§œì¦',
    # --- ì¼ë°˜ ì¤„ì„ë§ ---
    r'ê±': 'ê·¸ëƒ¥',
    r'ë„˜': 'ë„ˆë¬´',

    # ======================================================
    # 4. ê°ì • í‘œí˜„ ì´ëª¨í‹°ì½˜ ë° ê¸°íƒ€
    # ======================================================
    r'\bã…‹\b': 'ë¹„ì›ƒìŒ',
    r'[ã…‹]{2,}': 'ì›ƒìŒ',
    r'[ã…]{2,}': 'ì›ƒìŒ',
    r'[ã… ã…œ]{2,}': 'ìŠ¬í””',
    r'[!?]{2,}': 'ê°•ì¡°',
    r'[ã…¡]{2,}|--': 'ë¶ˆë§Œ',
    r'\^\^': 'ë¯¸ì†Œ',
    r'ã„·ã„·': 'ë†€ëŒ',
}

def preprocess_text(text):
    """
    ëŒ“ê¸€ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
    1. ìš•ì„¤, ì€ì–´, ì¤„ì„ë§ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.
    2. 'ê°œ' ì ‘ë‘ì‚¬ ë° '~ì¶©', '~ë†ˆ' ë“± ì ‘ë¯¸ì‚¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    3. ë°˜ë³µë˜ëŠ” ììŒ, ëª¨ìŒ, íŠ¹ìˆ˜ë¬¸ìë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    4. ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    5. ê³¼ë„í•œ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.
    6. ê°ì„± ì‚¬ì „ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì • ë¼ë²¨ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    text = str(text).lower()

    # 1. ì •ê·œí™” ì‚¬ì „ ì ìš©
    for pattern, replacement in normalization_dict.items():
        try:
            text = re.sub(pattern, replacement, text)
        except re.error:
            continue

    # 2. ì ‘ë‘ì‚¬ ë° ì ‘ë¯¸ì‚¬ ì²˜ë¦¬
    text = re.sub(r'\bê°œ(?!ìƒˆ)', 'ë§¤ìš° ', text)
    text = re.sub(r'[ê°€-í£]+ì¶©\b', ' ë¹„í•˜', text)
    text = re.sub(r'[ê°€-í£]+(ë†ˆ|ë…„)\b', ' ì‚¬ëŒ', text)

    # 3. ë°˜ë³µ ë¬¸ì ì²˜ë¦¬
    text = re.sub(r'([ã…‹ã…])\1{1,}', ' ì›ƒìŒ ', text)
    text = re.sub(r'([ã… ã…œ])\1{1,}', ' ìŠ¬í”” ', text)
    text = re.sub(r'([ã…-ã…£])\1{2,}', r'\1', text)
    text = re.sub(r'([!?.,])\1{1,}', r'\1', text)

    # 4. ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\s.?!ê°€-í£]', ' ', text)

    # 5. ê³¼ë„í•œ ê³µë°± ì œê±°
    text = re.sub(r'\s{2,}', ' ', text).strip()

    # 6. ê°ì„± ì‚¬ì „ ê¸°ë°˜ ë¼ë²¨ë§
    found_emotions = []
    for emotion, keywords in emotion_dict.items():
        for keyword in keywords:
            if keyword in text:
                found_emotions.append(emotion)
                break  # í•œ ê°ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ë‹¨ì–´ê°€ ë°œê²¬ë˜ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë„˜ì–´ê°

    if found_emotions:
        # ì¤‘ë³µì„ ì œê±°í•˜ê³  ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        unique_emotions = sorted(list(set(found_emotions)))
        emotion_label = f" (ê°ì •: {', '.join(unique_emotions)})"
        text += emotion_label

    return text

def process_row(row):
    comment = str(row.get('comment', ''))
    processed_comment = preprocess_text(comment)
    if processed_comment:
        return {'date': row.get('date'), 'comment': processed_comment}
    return None

def process_file_parallel(input_path):
    try:
        try:
            df = pd.read_csv(os.path.join('split_data', input_path), encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(os.path.join('split_data', input_path), encoding='cp949')
        
        rows = df.to_dict(orient='records')
        with Pool(cpu_count()) as pool:
            results = pool.map(process_row, rows)
        
        filtered_results = [r for r in results if r is not None]
        return pd.DataFrame(filtered_results)
    except FileNotFoundError:
        print(f"ê²½ê³ : {input_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

def main():
    print(f"ì „ì²˜ë¦¬ ì‹œì‘: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    input_dir = 'split_data'
    output_dir = 'processed_comments'
    os.makedirs(output_dir, exist_ok=True)

    input_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]
    
    all_processed_dfs = []
    for file_name in input_files:
        print(f"â–¶ ì²˜ë¦¬ ì‹œì‘: {file_name}")
        file_path = os.path.join(input_dir, file_name)
        processed_df = process_file_parallel(file_name) # file_nameë§Œ ì „ë‹¬

        if not processed_df.empty:
            print(f"âœ… {file_name} ì²˜ë¦¬ ì™„ë£Œ, ê±´ìˆ˜: {len(processed_df)}")
            output_path = os.path.join(output_dir, f'processed_{file_name}')
            processed_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            all_processed_dfs.append(processed_df)
        else:
            print(f"âš ï¸ {file_name} ì²˜ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    if all_processed_dfs:
        final_df = pd.concat(all_processed_dfs, ignore_index=True)
        final_output_path = os.path.join(output_dir, 'final_processed_comments.csv')
        final_df.to_csv(final_output_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ‰ ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ë° ë³‘í•© ì™„ë£Œ, ì´ ê±´ìˆ˜: {len(final_df)}")
    else:
        print("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ì–´ ìµœì¢… íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print(f"ì „ì²˜ë¦¬ ì¢…ë£Œ: {time.strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()