import pandas as pd
import multiprocessing as mp
from transformers import pipeline
from tqdm import tqdm
import os

# âœ… Step 1: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
CSV_PATH = "comment_only.csv"  # ì—¬ê¸°ì— íŒŒì¼ëª… ë„£ê¸°
COMMENT_COLUMN = "comment"  # ëŒ“ê¸€ì´ ë‹´ê¸´ ì»¬ëŸ¼ëª… (ì˜ˆ: "ë‚´ìš©", "text")

CHUNK = 10000  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„° ê°œìˆ˜

df = pd.read_csv(CSV_PATH)
texts = df[COMMENT_COLUMN].dropna().tolist()

# âœ… Step 2: ê°ì • ë ˆì´ë¸” ì •ì˜
labels = ["ê¸ì •", "ë¶€ì •", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ê¸°ëŒ€", "ì¤‘ë¦½"]

# âœ… Step 3: ì›Œì»¤ í•¨ìˆ˜ (í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ ì‹¤í–‰ë¨)
def analyze_sentiment(text):
    try:
        local_classifier = pipeline(
            "zero-shot-classification",
            model="joeddav/xlm-roberta-large-xnli",
            device=0,  # GPU ì‚¬ìš©
            use_fast=False
        )
        result = local_classifier(text, labels)
        return {
            'text': text,
            'top_emotion': result['labels'][0],
            **{label: result['scores'][i] for i, label in enumerate(result['labels'])}
        }
    except Exception as e:
        return {
            'text': text,
            'top_emotion': 'error',
            **{label: None for label in labels}
        }

# âœ… Step 4: ë³‘ë ¬ ì‹¤í–‰ ë° ì²­í¬ë³„ ì €ì¥
if __name__ == "__main__":
    print("ğŸ§  í”„ë¡œì„¸ìŠ¤ ìˆ˜:", mp.cpu_count())
    total = len(texts)
    num_chunks = (total + CHUNK - 1) // CHUNK

    for i in range(num_chunks):
        chunk_texts = texts[i*CHUNK:(i+1)*CHUNK]
        print(f"â–¶ï¸ {i+1}/{num_chunks}ë²ˆì§¸ ì²­í¬ ì²˜ë¦¬ ì¤‘... ({len(chunk_texts)}ê°œ)")
        with mp.Pool(processes=mp.cpu_count() - 1) as pool:
            results = list(tqdm(pool.imap(analyze_sentiment, chunk_texts), total=len(chunk_texts)))
        result_df = pd.DataFrame(results)
        result_df.to_csv(f"ê°ì •ë¶„ì„_ê²°ê³¼_{i+1:02d}.csv", index=False)
        print(f"âœ… ê°ì •ë¶„ì„_ê²°ê³¼_{i+1:02d}.csv ì €ì¥ ì™„ë£Œ")

    print("ğŸ‰ ì „ì²´ ê°ì •ë¶„ì„ ì™„ë£Œ ë° íŒŒì¼ ë¶„í•  ì €ì¥ë¨!")